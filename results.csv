,path,peft,md_nm,ds,up,test_date,train_date,machine,metric,score
0,"eval/24-11-26_{peft=lora, md_nm=flan-t5-base, ds=hatexplain, up=True}_UserProfle-Eval-24-11-27",lora,flan-t5-base,hatexplain,True,24-11-27,24-11-26,clarity2,accuracy,56.1
1,"eval/24-11-26_{peft=lora, md_nm=flan-t5-base, ds=parenting, up=True}_UserProfle-Eval-24-11-27",lora,flan-t5-base,parenting,True,24-11-27,24-11-26,clarity2,rouge,"{'rouge1': {'precision': '43.1', 'recall': '3.3', 'fmeasure': '4.9'}, 'rouge2': {'precision': '4.0', 'recall': '0.4', 'fmeasure': '0.6'}, 'rougeL': {'precision': '37.8', 'recall': '2.3', 'fmeasure': '3.4'}"
2,"eval/24-11-26_{peft=lora, md_nm=flan-t5-base, ds=interpersonal, up=True}_UserProfle-Eval-24-11-27",lora,flan-t5-base,interpersonal,True,24-11-27,24-11-26,clarity2,rouge,"{'rouge1': {'precision': '51.8', 'recall': '5.3', 'fmeasure': '8.1'}, 'rouge2': {'precision': '9.6', 'recall': '0.8', 'fmeasure': '1.2'}, 'rougeL': {'precision': '41.0', 'recall': '3.3', 'fmeasure': '5.2'}"
3,"eval/24-11-26_{peft=lora, md_nm=flan-t5-base, ds=tweeteval, up=True}_UserProfle-Eval-24-11-27",lora,flan-t5-base,tweeteval,True,24-11-27,24-11-26,clarity2,accuracy,66.2
4,"eval/24-11-26_{peft=lora, md_nm=flan-t5-base, ds=subjectivediscourse_question_sentiment, up=True}_UserProfle-Eval-24-11-27",lora,flan-t5-base,subjectivediscourse_question_sentiment,True,24-11-27,24-11-26,clarity2,accuracy,24.1
5,"eval/24-11-26_{peft=lora, md_nm=flan-t5-base, ds=philosophy, up=True}_UserProfle-Eval-24-11-27",lora,flan-t5-base,philosophy,True,24-11-27,24-11-26,clarity2,rouge,"{'rouge1': {'precision': '34.1', 'recall': '3.8', 'fmeasure': '5.6'}, 'rouge2': {'precision': '4.0', 'recall': '0.4', 'fmeasure': '0.7'}, 'rougeL': {'precision': '28.3', 'recall': '2.7', 'fmeasure': '4.1'}"
6,"eval/24-11-26_{peft=lora, md_nm=flan-t5-base, ds=studemo, up=True}_UserProfle-Eval-24-11-27",lora,flan-t5-base,studemo,True,24-11-27,24-11-26,clarity2,accuracy,69.8
7,"eval/24-11-26_{peft=lora, md_nm=flan-t5-base, ds=epic, up=True}_UserProfle-Eval-24-11-27",lora,flan-t5-base,epic,True,24-11-27,24-11-26,clarity2,accuracy,68.2
8,"eval/24-11-26_{peft=lora, md_nm=flan-t5-base, ds=judaism, up=True}_UserProfle-Eval-24-11-27",lora,flan-t5-base,judaism,True,24-11-27,24-11-26,clarity2,rouge,"{'rouge1': {'precision': '29.8', 'recall': '3.8', 'fmeasure': '5.1'}, 'rouge2': {'precision': '2.2', 'recall': '0.3', 'fmeasure': '0.5'}, 'rougeL': {'precision': '26.6', 'recall': '2.9', 'fmeasure': '3.9'}"
9,"eval/24-11-26_{peft=lora, md_nm=flan-t5-base, ds=gabhate, up=True}_UserProfle-Eval-24-11-27",lora,flan-t5-base,gabhate,True,24-11-27,24-11-26,clarity2,accuracy,88.8
10,"eval/24-11-26_{peft=lora, md_nm=flan-t5-base, ds=subjectivediscourse_response, up=True}_UserProfle-Eval-24-11-27",lora,flan-t5-base,subjectivediscourse_response,True,24-11-27,24-11-26,clarity2,accuracy,28.7
11,"eval/24-11-26_{peft=lora, md_nm=flan-t5-base, ds=subjectivediscourse_response_sentiment, up=True}_UserProfle-Eval-24-11-27",lora,flan-t5-base,subjectivediscourse_response_sentiment,True,24-11-27,24-11-26,clarity2,accuracy,13.8
12,"eval/24-11-26_{peft=lora, md_nm=flan-t5-base, ds=travel, up=True}_UserProfle-Eval-24-11-27",lora,flan-t5-base,travel,True,24-11-27,24-11-26,clarity2,rouge,"{'rouge1': {'precision': '34.8', 'recall': '5.0', 'fmeasure': '7.2'}, 'rouge2': {'precision': '2.5', 'recall': '0.5', 'fmeasure': '0.7'}, 'rougeL': {'precision': '29.7', 'recall': '3.4', 'fmeasure': '5.0'}"
13,"eval/24-11-25_{peft=lora, md_nm=flan-t5-base, ds=goemotion, up=True}_UserProfle-Eval-24-11-27",lora,flan-t5-base,goemotion,True,24-11-27,24-11-25,clarity2,accuracy,65.6
